{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Data Understanding\n",
    "\n",
    "The Dataset used was from Kaggle,(https://www.kaggle.com/datasets/ruchi798/bookcrossing-dataset?select=Books+Data+with+Category+Language+and+Summary) extracted in csv form and excel form (both in text form) and containing important information with regards to Book Summary and Category which were the primary basis for perfoming Natural Language Processing, inorder to recommend similar books. The Dataset contains 1,031,175 books. I used the Csv (Comma Separated Values) form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       Importing Libraries for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk   # the natural language toolkit for natural language processing tasks inthis project\n",
    "import pandas as pd  \n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer # for sentiment analysis\n",
    "from nltk.tokenize import word_tokenize, blankline_tokenize # for word tokenization and blank lines tokenization\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re # regular expression module for pattern matching\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "nltk.download(\"vader_lexicon\") # Valence Aware Dictionary and sEntiment Reasoner Lexicon for sentiment analysis\n",
    "nltk.download(\"punkt\")  # downloading punkt models for tokenization\n",
    "nltk.download(\"wordnet\") # downloading wordnet, a lexical database for Lemmatization\n",
    "nltk.download(\"stopwords\") # downloading common stop words in English such as \"the\", \"and\" etc which I will remove as they carry no meaning in NLP\n",
    "nltk.download(\"omw-1.4\") # downloading Open Multilingual Wordnet dataset for lemmatization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>publisher</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1031170</th>\n",
       "      <td>0</td>\n",
       "      <td>As Hogan Said . . . : The 389 Best Things Anyo...</td>\n",
       "      <td>Randy Voorhees</td>\n",
       "      <td>Simon &amp; Schuster</td>\n",
       "      <td>Golf lovers will revel in this collection of t...</td>\n",
       "      <td>['Humor']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031171</th>\n",
       "      <td>5</td>\n",
       "      <td>All Elevations Unknown: An Adventure in the He...</td>\n",
       "      <td>Sam Lightner</td>\n",
       "      <td>Broadway Books</td>\n",
       "      <td>A daring twist on the travel-adventure genre t...</td>\n",
       "      <td>['Nature']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031172</th>\n",
       "      <td>7</td>\n",
       "      <td>Why stop?: A guide to Texas historical roadsid...</td>\n",
       "      <td>Claude Dooley</td>\n",
       "      <td>Lone Star Books</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031173</th>\n",
       "      <td>7</td>\n",
       "      <td>The Are You Being Served? Stories: 'Camping In...</td>\n",
       "      <td>Jeremy Lloyd</td>\n",
       "      <td>Kqed Books</td>\n",
       "      <td>These hilarious stories by the creator of publ...</td>\n",
       "      <td>['Fiction']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031174</th>\n",
       "      <td>10</td>\n",
       "      <td>Dallas Street Map Guide and Directory, 2000 Ed...</td>\n",
       "      <td>Mapsco</td>\n",
       "      <td>American Map Corporation</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating                                         book_title  \\\n",
       "1031170       0  As Hogan Said . . . : The 389 Best Things Anyo...   \n",
       "1031171       5  All Elevations Unknown: An Adventure in the He...   \n",
       "1031172       7  Why stop?: A guide to Texas historical roadsid...   \n",
       "1031173       7  The Are You Being Served? Stories: 'Camping In...   \n",
       "1031174      10  Dallas Street Map Guide and Directory, 2000 Ed...   \n",
       "\n",
       "            book_author                 publisher  \\\n",
       "1031170  Randy Voorhees          Simon & Schuster   \n",
       "1031171    Sam Lightner            Broadway Books   \n",
       "1031172   Claude Dooley           Lone Star Books   \n",
       "1031173    Jeremy Lloyd                Kqed Books   \n",
       "1031174          Mapsco  American Map Corporation   \n",
       "\n",
       "                                                   Summary     Category  \n",
       "1031170  Golf lovers will revel in this collection of t...    ['Humor']  \n",
       "1031171  A daring twist on the travel-adventure genre t...   ['Nature']  \n",
       "1031172                                                  9            9  \n",
       "1031173  These hilarious stories by the creator of publ...  ['Fiction']  \n",
       "1031174                                                  9            9  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "file_path = r\"C:\\Users\\user\\Desktop\\book_summary_dataset.csv\"\n",
    "# The \"r\" string prefix notation i used when opening this file was to ensure \"\\\" was not intepreted as mode but as the normal symbol\n",
    "\n",
    "\n",
    "books = pd.read_csv(file_path)\n",
    "\n",
    "books.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       Getting the summary of the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1031175 entries, 0 to 1031174\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count    Dtype \n",
      "---  ------       --------------    ----- \n",
      " 0   rating       1031175 non-null  int64 \n",
      " 1   book_title   1031175 non-null  object\n",
      " 2   book_author  1031175 non-null  object\n",
      " 3   publisher    1031175 non-null  object\n",
      " 4   Summary      1031175 non-null  object\n",
      " 5   Category     1031175 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 47.2+ MB\n"
     ]
    }
   ],
   "source": [
    "books.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            Getting the number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1031175, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.shape\n",
    "\n",
    "# There are 1,031,175 rows and 6 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          Checking for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     589421\n",
       "False    441754\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.duplicated().value_counts()\n",
    "\n",
    "# There are 589421 duplicated values which is a huge number "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Dropping duplicates\n",
    "Some books were recorded multiple times as in the case from index 1 to index 4 which were recorded four times or more. Therefore; this will lead to reducing the number of books "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>publisher</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>Provides an introduction to classical myths pl...</td>\n",
       "      <td>['Social Science']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "      <td>['Actresses']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>Here, for the first time in paperback, is an o...</td>\n",
       "      <td>['1940-1949']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>Describes the great flu epidemic of 1918, an o...</td>\n",
       "      <td>['Medical']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>W. W. Norton &amp; Company</td>\n",
       "      <td>A look at the incredibly well-preserved ancien...</td>\n",
       "      <td>['Design']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rating                                         book_title  \\\n",
       "0        0                                Classical Mythology   \n",
       "1        5                                       Clara Callan   \n",
       "15       0                               Decision in Normandy   \n",
       "18       0  Flu: The Story of the Great Influenza Pandemic...   \n",
       "29       0                             The Mummies of Urumchi   \n",
       "\n",
       "             book_author                publisher  \\\n",
       "0     Mark P. O. Morford  Oxford University Press   \n",
       "1   Richard Bruce Wright    HarperFlamingo Canada   \n",
       "15          Carlo D'Este          HarperPerennial   \n",
       "18      Gina Bari Kolata     Farrar Straus Giroux   \n",
       "29       E. J. W. Barber   W. W. Norton & Company   \n",
       "\n",
       "                                              Summary            Category  \n",
       "0   Provides an introduction to classical myths pl...  ['Social Science']  \n",
       "1   In a small town in Canada, Clara Callan reluct...       ['Actresses']  \n",
       "15  Here, for the first time in paperback, is an o...       ['1940-1949']  \n",
       "18  Describes the great flu epidemic of 1918, an o...         ['Medical']  \n",
       "29  A look at the incredibly well-preserved ancien...          ['Design']  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "book_df = books.drop_duplicates(subset=[\"book_title\", \"book_author\", \"publisher\"]) #books containing same info on book title, book author and publisher, to be removed\n",
    "\n",
    "book_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 264984 entries, 0 to 1031174\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   rating       264984 non-null  int64 \n",
      " 1   book_title   264984 non-null  object\n",
      " 2   book_author  264984 non-null  object\n",
      " 3   publisher    264984 non-null  object\n",
      " 4   Summary      264984 non-null  object\n",
      " 5   Category     264984 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 14.2+ MB\n"
     ]
    }
   ],
   "source": [
    "book_df.info() #from below the dataframe now has 264,984 books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "           Checking for missing values in each colmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating         0\n",
       "book_title     0\n",
       "book_author    0\n",
       "publisher      0\n",
       "Summary        0\n",
       "Category       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "           Removing columns that have less use in this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df.drop(columns=[\"rating\", \"publisher\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>Provides an introduction to classical myths pl...</td>\n",
       "      <td>Social Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "      <td>Actresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>Here, for the first time in paperback, is an o...</td>\n",
       "      <td>1940-1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>Describes the great flu epidemic of 1918, an o...</td>\n",
       "      <td>Medical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>A look at the incredibly well-preserved ancien...</td>\n",
       "      <td>Design</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           book_title           book_author  \\\n",
       "0                                 Classical Mythology    Mark P. O. Morford   \n",
       "1                                        Clara Callan  Richard Bruce Wright   \n",
       "15                               Decision in Normandy          Carlo D'Este   \n",
       "18  Flu: The Story of the Great Influenza Pandemic...      Gina Bari Kolata   \n",
       "29                             The Mummies of Urumchi       E. J. W. Barber   \n",
       "\n",
       "                                              Summary            Category  \n",
       "0   Provides an introduction to classical myths pl...    Social Science    \n",
       "1   In a small town in Canada, Clara Callan reluct...         Actresses    \n",
       "15  Here, for the first time in paperback, is an o...         1940-1949    \n",
       "18  Describes the great flu epidemic of 1918, an o...           Medical    \n",
       "29  A look at the incredibly well-preserved ancien...            Design    "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting Category from a list of string to string; by removing square brackets\n",
    "\n",
    "book_df['Category'] = book_df['Category'].apply(lambda x: re.sub(r'\\[|\\]|\\'|\\s', ' ', x))\n",
    "\n",
    "book_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27000 entries, 0 to 461621\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   book_title   27000 non-null  object\n",
      " 1   book_author  27000 non-null  object\n",
      " 2   Summary      27000 non-null  object\n",
      " 3   Category     27000 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "book_slicing = book_df.iloc[0:27000, 0:4] #Reducing the df size to 27,000 books to reduce memory therefore avoiding computational complexities ahead\n",
    "\n",
    "book_slicing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Using the preprocess_text Function for nltk preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classical mythology</td>\n",
       "      <td>mark p morford</td>\n",
       "      <td>provides introduction classical myth placing a...</td>\n",
       "      <td>social science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clara callan</td>\n",
       "      <td>richard bruce wright</td>\n",
       "      <td>small town canada clara callan reluctantly tak...</td>\n",
       "      <td>actress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>decision normandy</td>\n",
       "      <td>carlo este</td>\n",
       "      <td>first time paperback outstanding military hist...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>flu story great influenza pandemic search viru...</td>\n",
       "      <td>gina bari kolata</td>\n",
       "      <td>describes great flu epidemic outbreak killed f...</td>\n",
       "      <td>medical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>mummy urumchi</td>\n",
       "      <td>e j w barber</td>\n",
       "      <td>look incredibly well preserved ancient mummy f...</td>\n",
       "      <td>design</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           book_title           book_author  \\\n",
       "0                                 classical mythology        mark p morford   \n",
       "1                                        clara callan  richard bruce wright   \n",
       "15                                  decision normandy            carlo este   \n",
       "18  flu story great influenza pandemic search viru...      gina bari kolata   \n",
       "29                                      mummy urumchi          e j w barber   \n",
       "\n",
       "                                              Summary        Category  \n",
       "0   provides introduction classical myth placing a...  social science  \n",
       "1   small town canada clara callan reluctantly tak...         actress  \n",
       "15  first time paperback outstanding military hist...                  \n",
       "18  describes great flu epidemic outbreak killed f...         medical  \n",
       "29  look incredibly well preserved ancient mummy f...          design  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Initializing the Stopwords,Lemmatizer and analyzer\n",
    "\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    " \n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "sia=SentimentIntensityAnalyzer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text=re.sub(r\"[^a-zA-Z]\", \" \", text)  # Removing special characters/non-alphabetical characters from the text.\n",
    "    tokens = text.split()      #splitting into tokens\n",
    "    tokens=word_tokenize(text.lower())  # tokenizing the words and converting to lower case\n",
    "    tokens=[t for t in tokens if t not in stop_words] # removing stop words\n",
    "    tokens= [lemmatizer.lemmatize(t) for t in tokens] #Lemmatizing the tokens\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def preprocess_df(df_name, column):\n",
    "    if df_name[column].dtype == \"object\": #\"object\" data type is used as a container for various non-numeric types of data. \n",
    "        df_name[column] = df_name[column].apply(lambda x: preprocess_text(str(x)))\n",
    "    return df_name\n",
    "\n",
    "\n",
    "new_book_df= preprocess_df(book_slicing, \"book_title\")\n",
    "new_book_df= preprocess_df(book_slicing,\"book_author\")\n",
    "new_book_df=preprocess_df(book_slicing, \"Summary\")\n",
    "new_book_df=preprocess_df(book_slicing,\"Category\")\n",
    "\n",
    "new_book_df.head()\n",
    "\n",
    "\n",
    "# summary and category had numerical values which were converted to space and hence no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "         Creating a new column called \"book_info\" that contains Summary and Book Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'provides introduction classical myth placing addressed topic within historical context discussion archaeological evidence support mythical event theme portrayed literature art social science'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_book_df[\"book_info\"]=new_book_df[\"Summary\"] + \" \" + new_book_df[\"Category\"]\n",
    "\n",
    "\n",
    "new_book_df.drop(columns=[\"Summary\", \"Category\"], inplace=True)\n",
    "\n",
    "new_book_df[\"book_info\"][0] # preview the first book_info row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I) Data Vectorization\n",
    "\n",
    "Text data in the \"new_book_df\" dataframe is transformed into numerical vectors to make it suitable for mathematical\n",
    "operations.\n",
    "Techniques I used for vectorization are TF-IDF \n",
    "(Term Frequency-Inverse Document Frequency) Vectorization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       Term Frequency (TF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will measure the frequency of terms (tokens/words). Words that appear frequently within single document but rare acrosss the corpus are assigned higher scores. this will help to capture the uniqueness of terms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      Inverse Document Frequency (IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDF measures the importance of a term across a collection of documents (corpus). IDF has an inverse relationship with the number of documents containing the term. If a term appears in many documents (high document frequency), its IDF value will be lower because it is considered less important for distinguishing documents. The primary purpose of IDF is to identify terms that are discriminative or rare in the corpus, giving them higher weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      TF-IDF Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TF-IDF score for a term in a document combines both term frequency and inverse document frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 189685)\t0.10576753329233111\n",
      "  (0, 10475)\t0.17596808362257044\n",
      "  (0, 119929)\t0.1830288257081547\n",
      "  (0, 156479)\t0.1830288257081547\n",
      "  (0, 205149)\t0.1830288257081547\n",
      "  (0, 68145)\t0.1830288257081547\n",
      "  (0, 137910)\t0.1830288257081547\n",
      "  (0, 199746)\t0.1830288257081547\n",
      "  (0, 68341)\t0.17596808362257044\n",
      "  (0, 9409)\t0.1830288257081547\n",
      "  (0, 56396)\t0.1830288257081547\n",
      "  (0, 41538)\t0.1830288257081547\n",
      "  (0, 93958)\t0.17596808362257044\n",
      "  (0, 208195)\t0.1830288257081547\n",
      "  (0, 2265)\t0.1830288257081547\n",
      "  (0, 153765)\t0.1830288257081547\n",
      "  (0, 137887)\t0.1830288257081547\n",
      "  (0, 35593)\t0.1830288257081547\n",
      "  (0, 104259)\t0.1830288257081547\n",
      "  (0, 161707)\t0.1830288257081547\n",
      "  (0, 180565)\t0.0902495489233351\n",
      "  (0, 189613)\t0.09648483161322553\n",
      "  (0, 10362)\t0.09448759558190829\n",
      "  (0, 119926)\t0.11308780227763199\n",
      "  (0, 156475)\t0.1550021822924483\n",
      "  :\t:\n",
      "  (26997, 146122)\t0.25852378884240157\n",
      "  (26997, 58537)\t0.24855066144598337\n",
      "  (26997, 164451)\t0.24855066144598337\n",
      "  (26997, 13746)\t0.24147461494813813\n",
      "  (26997, 184346)\t0.22770988048758847\n",
      "  (26997, 58534)\t0.2315014875517199\n",
      "  (26997, 152213)\t0.19361153269906153\n",
      "  (26997, 211129)\t0.17791665085430838\n",
      "  (26997, 194008)\t0.20188765908842757\n",
      "  (26997, 219816)\t0.1502832185335096\n",
      "  (26997, 13702)\t0.11839375547078598\n",
      "  (26997, 184247)\t0.12481819409780273\n",
      "  (26997, 84157)\t0.16408570704387904\n",
      "  (26997, 163984)\t0.1990700690429077\n",
      "  (26997, 145983)\t0.11738306445432939\n",
      "  (26997, 75466)\t0.049362761720777276\n",
      "  (26998, 26484)\t0.4009763583314114\n",
      "  (26998, 123763)\t0.4009763583314114\n",
      "  (26998, 95842)\t0.4009763583314114\n",
      "  (26998, 26482)\t0.374532696449107\n",
      "  (26998, 123762)\t0.3395760768751867\n",
      "  (26998, 34735)\t0.34359559528331196\n",
      "  (26998, 95830)\t0.3061768221016007\n",
      "  (26998, 34646)\t0.2107206407476773\n",
      "  (26998, 75466)\t0.07656278178734507\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "tf = TfidfVectorizer(analyzer=\"word\", ngram_range=(1,2), min_df=0, stop_words=\"english\") #analyzer will use words/tokens, ngram_range=(1,2) meaning both unigrams(single word) and \n",
    "                                                                                     # bigrams (2 adjacent words) should be considered. minimum_document frequency=0 meaning words that appear only in a single corpus to be also considered.\n",
    "# Converting the vectors into Tf_Idf Matrix\n",
    "tfidf_matrix = tf.fit_transform(new_book_df[\"book_info\"]) #if Double brackets to show its a list of columns\n",
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II) Dimensionality Reduction\n",
    "\n",
    "Since book data is high dimensional, It will be necessary for me to reduce the number of features to avoid computational complexities when getting the cosine similarity.Important information will be preserved. Otherwise; attempting without reducing the number of documents will return \"Memory Error\"\n",
    "\n",
    "    Latent Semantic Analysis\n",
    "LSA for analysing r/ship between words and undelying patterns of word co-occurence in the documents, while retrieving important information.\n",
    "I used Truncated Singular Value Decomposition (which is the mathematical basis for LSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd=TruncatedSVD(n_components= 100, random_state=42)\n",
    "tfidf_svd=svd.fit_transform(tfidf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "III) Cosine Similarity:\n",
    "\n",
    "After vectorization, you have numerical representations of text documents. These vectors can be considered as points in a high-dimensional space.\n",
    "Cosine similarity measures the cosine of the angle between two vectors. The cosine of 0 degrees is 1, and the cosine of 90 degrees is 0. In other words, if two vectors have a cosine similarity of 1, they point in the same direction (high similarity), and if the cosine similarity is 0, they are orthogonal (no similarity).\n",
    "In the context of NLP, cosine similarity calculates how similar two text documents are based on their vector representations. If the vectors point in a similar direction, they have a higher cosine similarity, indicating that the documents are more similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_similarity=cosine_similarity(tfidf_svd, tfidf_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IV) Converting Book Title column to Series \"indices\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91968                                        hallowed grnd\n",
       "91969    woman war essential voice nuclear age brillian...\n",
       "91971                                        lonesome dove\n",
       "92045                                       bitter harvest\n",
       "92114                       sex art american culture essay\n",
       "92132            little woman treasury illustrated classic\n",
       "92135    swiss family robinson treasury illustrated cla...\n",
       "Name: book_title, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices=pd.Series(new_book_df[\"book_title\"]) \n",
    "indices[1900:1907]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 Book Recommender System\n",
    "Takes 2 params; book_title (which I want to find recommendations) and cosine similarity score for books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(book_title, cos_similarity=cos_similarity):\n",
    "    if book_title not in indices.values:\n",
    "        return \"Book title does not exist in my Book Catalogue. Please contact Isaac for the book to be added.\"\n",
    "    recommended_books = []\n",
    "    idx = indices[indices == book_title].index[0]   # to get the index of book title matching the input\n",
    "    score_series = pd.Series(cos_similarity[idx]).sort_values(ascending = False)   # similarity scores in descending order\n",
    "    top_5_indices = list(score_series.iloc[1:6].index)   # to get the indices of top 5 most similar books\n",
    "    # [1:6] to exclude 0 (index 0 is the input book itself)\n",
    "    \n",
    "    for i in top_5_indices:   # to append the titles of top 5 similar books\n",
    "        recommended_books.append(list(book_df[\"book_title\"])[i])\n",
    "        \n",
    "    return recommended_books\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try to Recommend 5 other similar books, by giving the Book Title as Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Something Special: A Story',\n",
       " 'The Doors of Perception and Heaven and Hell',\n",
       " 'Island',\n",
       " 'Der Kleine Prinz, Mit Zeichnungen Des Verfassers (Harbrace Paperbound Library)',\n",
       " 'Blood Shot (V.I. Warshawski Novels (Paperback))']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(\"mummy urumchi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kaaterskill Falls',\n",
       " 'Too Close to the Falls: A Memoir',\n",
       " 'Sleepwalk',\n",
       " 'LAKE NEWS : A Novel',\n",
       " 'Extra Virgin: A Young Woman Discovers the Italian Riviera, Where Every Month Is Enchanted']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(\"clara callan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me try recommending a book that I'm pretty sure is not in my catalogue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Book title does not exist in my Book Catalogue. Please contact Isaac for the book to be added.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(\"mstahiki meya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gay Ideas: Outing and Other Controversies',\n",
       " 'Walden Two (Trade Book)',\n",
       " 'The Community in America',\n",
       " 'A Certain People: American Jews and Their Lives Today',\n",
       " 'Media Virus!: Hidden Agendas in Popular Culture']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(\"classical mythology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats all for now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
